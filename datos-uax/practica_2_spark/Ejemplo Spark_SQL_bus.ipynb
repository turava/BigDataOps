{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Contar c\u00faantos trayectos se han realizado en bus a cada uno de los destinos. Spark SQL\n\nEn este ejemplo, no se va a tener en cuenta los campos vacios, lo cual se deber\u00eda de tratar pero para simplificar vamos simplemente a saber la cantidad de trayectos a dicho destino \"sin importar su origen\"."}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------+----------+\n|   destination|dest_count|\n+--------------+----------+\n|     SAO PAULO|     17102|\n|RIO DE JANEIRO|     14299|\n|BELO HORIZONTE|      4626|\n|        RECIFE|      2874|\n| FLORIANOPOLIS|      2857|\n+--------------+----------+\nonly showing top 5 rows\n\n"}], "source": "# Asumimos que la sesi\u00f3n de Spark ya est\u00e1 inicializada y lista para ser utilizada.\n# Comenzamos el proceso importando los datos desde un archivo CSV:\nbus_tripsDF = spark.read\\\n .option(\"header\", \"true\")\\\n .csv(\"/Enric/bus_trips.csv\")\n\n# Es crucial en Spark SQL vincular el DataFrame a una vista temporal \n# para poder realizar consultas SQL directamente sobre los datos:\nbus_tripsDF.createOrReplaceTempView('bus_trips')\n\n# Realizamos una consulta SQL para identificar el n\u00famero de trayecto\n# que llegan a cada uno de los destinos de los buses.\n# Seleccionamos el destino y contabilizamos las ocurrencias, ordenando\n# los resultados de mayor a menor frecuencia:\nbus_trips_destination_count = spark.sql('SELECT destination, COUNT(destination) AS dest_count FROM bus_trips GROUP BY destination ORDER BY dest_count DESC')\n\n# Para manipulaciones o consultas futuras, es conveniente tener \n# esta consulta como una vista temporal en Spark SQL:\nbus_trips_destination_count.createOrReplaceTempView('bus_trips_destination_count')\n\n\n# verificamos los destinos m\u00e1s frecuentados en nuestro conjunto de datos de trayectos en bus:\nbus_trips_destination_count.show(5) # Exhibimos las primeras 5 filas de los resultados.\n"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.13"}}, "nbformat": 4, "nbformat_minor": 2}